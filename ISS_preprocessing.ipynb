{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1a828d-1e92-41cf-b3f9-dd844ba7789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISS_processing.preprocessing import preprocessing_main_leica\n",
    "import ISS_processing.preprocessing as pp\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb9d84eb-e56e-470e-ad85-1b2bce7e2ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = '/media/cml/hfsc_processing_2/HFSC'\n",
    "    \n",
    "input_dirs = [\n",
    "    '/media/cml/Roadrunner/220609_fetal_spinalcord_cycle_1/2022_06_09_17_26_34--220609_fetal_spinalcord_cycle_1001/TileScan 1/',\n",
    "    \n",
    "    '/media/cml/Roadrunner/220609_fetal_spinalcord_cycle_2/2022_06_09_13_04_07--220609_fetal_spinalcord_cycle_2001/TileScan 1/', \n",
    "    \n",
    "    '/media/cml/Roadrunner/220608_fetal_spinalcord_cycle_3/2022_06_08_18_48_18--220608_fetal_spinalcord_cycle_3001/TileScan 1/',\n",
    "    \n",
    "    '/media/cml/Roadrunner/220608_fetal_spinalcord_cycle_4/2022_06_08_14_14_38--220608_fetal_spinalcord_cycle_4001/TileScan 1/',\n",
    "    \n",
    "    '/media/cml/Roadrunner/220608_fetal_spinalcord_cycle_5/2022_06_08_09_48_57--220608_fetal_spinalcord_cycle_5001/TileScan 1',\n",
    "    \n",
    "    '/media/cml/Roadrunner/220607_fetal_spinalcord_cycle_6/2022_06_07_13_34_32--220607_fetal_spinalcord_cycle_6001/TileScan 1/'\n",
    "\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67c20c0-f9a6-46f4-8893-73a673d96dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.Trash-1000',\n",
       " 'HFSC_R1',\n",
       " 'HFSC_R2',\n",
       " 'HFSC_R3',\n",
       " 'HFSC_R4',\n",
       " 'HFSC_R5',\n",
       " 'HFSC_R6',\n",
       " 'HFSC_R7',\n",
       " 'HFSC_R8']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/media/cml/hfsc_processing_2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "266c0a0f-e4c3-48ef-ab66-988055844892",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ISS_processing.preprocessing as preprocessing\n",
    "import os\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "#import ashlar.scripts.ashlar as ashlar\n",
    "import re\n",
    "import mat73\n",
    "\n",
    "def zen_OME_tiff(exported_directory, output_directory, channel_split = 3, cycle_split = 2, num_channels = 5):\n",
    "    '''\n",
    "    using this function is predicated on the fact that you are using the nilsson SOP for naming files. this only works if we have rather small sections. \n",
    "    '''\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    import tifffile\n",
    "    import os\n",
    "    from os import listdir\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from xml.dom import minidom\n",
    "    from tqdm import tqdm\n",
    "\n",
    "\n",
    "    # make directory\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # find files\n",
    "    onlyfiles = listdir(exported_directory)\n",
    "    onlytifs =  [k for k in onlyfiles if '.tif' in k]\n",
    "    onlyfiles_df = pd.DataFrame(onlytifs)\n",
    "\n",
    "    onlyfiles_split_tiles = onlyfiles_df[0].str.split('m',expand=True)\n",
    "    onlyfiles_split_channel = onlyfiles_split_tiles[0].str.split('_',expand=True)\n",
    "\n",
    "    tiles = list(np.unique(onlyfiles_split_tiles[1]))\n",
    "    channels = list(np.unique(onlyfiles_split_channel[channel_split]))\n",
    "    rounds = list(np.unique(onlyfiles_split_channel[cycle_split]))\n",
    "\n",
    "    for i, round_number in enumerate(rounds):\n",
    "        onlytifs_round_filt = [l for l in onlytifs if 'Base_'+round_number+'_' in l]\n",
    "        metadatafiles =  [k for k in onlyfiles if 'info.xml' in k]\n",
    "        metadatafiles_filt =  [k for k in metadatafiles if '_'+round_number+'_' in k]\n",
    "\n",
    "        for p, meta in enumerate(metadatafiles_filt):\n",
    "            mydoc = minidom.parse(exported_directory +'/'+ meta)\n",
    "            tile =[]\n",
    "            x =[]\n",
    "            y =[]\n",
    "            items = mydoc.getElementsByTagName('Bounds')\n",
    "            for elem in items:\n",
    "                tile.append(int(elem.attributes['StartM'].value))\n",
    "                x.append(float(elem.attributes['StartX'].value))\n",
    "                y.append(float(elem.attributes['StartY'].value))\n",
    "            unique_tiles = list(np.unique(tile))\n",
    "            x_reformatted = (x[:len(unique_tiles)])    \n",
    "            y_reformatted = (y[:len(unique_tiles)])     \n",
    "            dictionary = {'x': x_reformatted, 'y': y_reformatted}  \n",
    "\n",
    "            df = pd.DataFrame(dictionary) \n",
    "            positions = np.array(df).astype(int)\n",
    "\n",
    "\n",
    "        with tifffile.TiffWriter(output_directory+'/cycle_'+str(round_number)+'.ome.tif', bigtiff=True) as tif:\n",
    "            for i in tqdm(range(len(sorted(tiles)))):\n",
    "                position = positions[i]\n",
    "                tile = tiles[i]\n",
    "\n",
    "                tile_filtered = [k for k in onlytifs_round_filt if 'm'+tile in k]\n",
    "                tile_filtered =  [k for k in tile_filtered if '._' not in k]\n",
    "                stacked = np.empty((num_channels, 2048, 2048))\n",
    "                for n,image_file in enumerate(sorted(tile_filtered)):\n",
    "                    image_int = tifffile.imread(join(exported_directory,image_file))\n",
    "                    stacked[n] = image_int.astype('uint16')\n",
    "                pixel_size = 0.1625\n",
    "                metadata = {\n",
    "                                'Pixels': {\n",
    "                                    'PhysicalSizeX': pixel_size,\n",
    "                                    'PhysicalSizeXUnit': 'µm',\n",
    "                                    'PhysicalSizeY': pixel_size,\n",
    "                                    'PhysicalSizeYUnit': 'µm'\n",
    "                                },\n",
    "                                'Plane': {\n",
    "                                    'PositionX': [position[0]*pixel_size]*stacked.shape[0],\n",
    "                                    'PositionY': [position[1]*pixel_size]*stacked.shape[0]\n",
    "                                }\n",
    "\n",
    "                            }\n",
    "                tif.write(stacked.astype('uint16'),metadata=metadata)\n",
    "\n",
    "            \n",
    "\n",
    "def leica_mipping(input_dirs, output_dir_prefix, image_dimension = [2048, 2048]):\n",
    "\n",
    "    '''\n",
    "\n",
    "    the input is a list of the file paths to the files.\n",
    "    used to MIP files from leica when exported as tiffs. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    import tifffile\n",
    "    from xml.dom import minidom\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from tifffile import imread\n",
    "    from tqdm import tqdm\n",
    "    import re\n",
    "    import shutil\n",
    "    # only needed on linux\n",
    "\n",
    "    input_dirs_reformatted = []\n",
    "    for i in input_dirs: \n",
    "        i = i.replace(\"%20\", \" \") # needs to be done in linux thanks to the spaces\n",
    "        input_dirs_reformatted.append(i)\n",
    "\n",
    "    for ö,i in enumerate(input_dirs_reformatted):\n",
    "        files = os.listdir(i)\n",
    "        tifs =  [k for k in files if 'dw' not in k] # filter for deconvolved images\n",
    "        tifs =  [k for k in tifs if '.tif' in k]\n",
    "        tifs =  [k for k in tifs if '.txt' not in k]\n",
    "        #tifs =  [k for k in tifs if 'Corrected' in k]\n",
    "        split_underscore = pd.DataFrame(tifs)[0].str.split('--', expand = True)\n",
    "        regions_int = list(split_underscore[0].unique())\n",
    "        regions = []\n",
    "        for j in regions_int:\n",
    "            regions.append(j)\n",
    "        regions = list(np.unique(regions))\n",
    "\n",
    "        # IF THE SCAN IS BIG ENOUGH, THE SECTION WILL BE DIVIDED INTO DIFFERENT REGIONS. THEREFORE WE NEED TO CHECK THIS IN THE FILES\n",
    "        for region in regions: \n",
    "            tifs_filt =  [k for k in tifs if region in k]\n",
    "            bases = str((ö)+1) #[i.split('/')[5].split('cycle')[1]]\n",
    "            split_underscore = pd.DataFrame(tifs_filt)[0].str.split('--', expand = True)\n",
    "            # GET TILES\n",
    "            tiles = sorted(split_underscore[1].unique())\n",
    "            tiles_df = pd.DataFrame(tiles)\n",
    "            tiles_df['indexNumber'] = [int(i.split('e')[-1]) for i in tiles_df[0]]\n",
    "            tiles_df.sort_values(by = ['indexNumber'], ascending = [True], inplace = True)\n",
    "            tiles_df.drop('indexNumber', 1, inplace = True)\n",
    "            tiles = list(tiles_df[0])\n",
    "\n",
    "            # GET CHANNELS\n",
    "            channels = split_underscore[3].unique()\n",
    "            if len(regions) == 1:\n",
    "                output_dir = output_dir_prefix\n",
    "                folder_output = output_dir + '/preprocessing/mipped/'\n",
    "            else: \n",
    "                output_dir = output_dir_prefix + '_R'+region.split('Region')[1].split('_')[0]\n",
    "                folder_output = output_dir + '/preprocessing/mipped/'\n",
    "            if not os.path.exists(folder_output):\n",
    "                os.makedirs(folder_output)\n",
    "\n",
    "            for ååå, w in enumerate(sorted(bases)):\n",
    "                imgs = []\n",
    "                if not os.path.exists(folder_output +'/Base_'+w):\n",
    "                            os.makedirs(folder_output +'/Base_'+w)\n",
    "                try: \n",
    "                    file_to_copy = join(i,'Metadata',([k for k in os.listdir(join(i,'Metadata')) if region in k][0]))\n",
    "                    #shutil.copytree(join(i,'Metadata'), join(folder_output,('Base_'+w),'MetaData'))\n",
    "                    if not os.path.exists(join(folder_output,('Base_'+w),'MetaData')):\n",
    "                            os.makedirs(join(folder_output,('Base_'+w),'MetaData'))\n",
    "                    shutil.copy(file_to_copy, join(folder_output,('Base_'+w),'MetaData'))\n",
    "                except FileExistsError:\n",
    "                    print(' ')\n",
    "\n",
    "                # LOOP OVER THE TILES TO MIP\n",
    "                for _tile in tqdm(range(len(tiles))):\n",
    "                    tile = tiles[_tile]\n",
    "                    tile_for_name = re.split('(\\d+)', tile)[1]\n",
    "                    strings_with_substring = [string for string in os.listdir(folder_output +'/Base_'+w) if str(tile_for_name) in string]\n",
    "\n",
    "                    # ENSURE THAT WE DO NOT CREATE FILES THAT HAVE ALREADY BEEN CREATED\n",
    "                    if len(strings_with_substring) < 5:\n",
    "                        tifs_base_tile = [k for k in tifs_filt if str(tile)+'--' in k]\n",
    "                        for å,z in enumerate(sorted(list(channels))):\n",
    "                            tifs_base_tile_channel = [k for k in tifs_base_tile if str(z) in k]\n",
    "                            # DEFINE IMAGE TO USE AS GROUND ZERO \n",
    "                            maxi = np.zeros((image_dimension[0],image_dimension[1]))\n",
    "                            for n,q in enumerate(tifs_base_tile_channel):\n",
    "\n",
    "                                try:\n",
    "                                    im_array = imread(i + '/' +q)\n",
    "                                except:\n",
    "                                    print('image corrupted, reading black file instead.')\n",
    "                                    im_array = np.zeros((image_dimension[0],image_dimension[1]))\n",
    "\n",
    "                                inds = im_array > maxi # find where image intensity > max intensity\n",
    "                                maxi[inds] = im_array[inds]\n",
    "                            maxi = maxi.astype('uint16')\n",
    "                            # WRITE FILE\n",
    "                            tifffile.imwrite(folder_output +'/Base_'+w+'/Base_'+w+'_s'+str(tile_for_name)+'_'+z, maxi)\n",
    "                    else: \n",
    "                        continue\n",
    "def leica_OME_tiff(directory_base, output_directory):\n",
    "\n",
    "    import tifffile\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from os.path import join\n",
    "    import tifffile\n",
    "    import os\n",
    "    from os import listdir\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from xml.dom import minidom\n",
    "    from pathlib import Path\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    folders = os.listdir(directory_base)\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "        \n",
    "    for folder in folders:\n",
    "        exported_directory = join(directory_base,folder)\n",
    "        onlyfiles = listdir(exported_directory)\n",
    "        onlytifs =  [k for k in onlyfiles if '.tif' in k]\n",
    "        onlyfiles_df = pd.DataFrame(onlytifs)\n",
    "        onlyfiles_split_tiles = onlyfiles_df[0].str.split('_s',expand=True)\n",
    "        onlyfiles_split_channel = onlyfiles_split_tiles[1].str.split('_',expand=True)\n",
    "\n",
    "        tiles = list(np.unique(onlyfiles_split_tiles[1].str.split('_',expand=True)[0]))\n",
    "        tiles_df=pd.DataFrame(tiles)\n",
    "        tiles_df['indexNumber'] = [int(i.split('e')[-1]) for i in tiles_df[0]]\n",
    "        # Perform sort of the rows\n",
    "        tiles_df.sort_values(by = ['indexNumber'], ascending = [True], inplace = True)\n",
    "        # Deletion of the added column\n",
    "        tiles_df.drop('indexNumber', 1, inplace = True)\n",
    "        tiles = list(tiles_df[0])\n",
    "        channels = list(np.unique(onlyfiles_split_channel[1]))\n",
    "        rounds = list(np.unique(onlyfiles_split_tiles[0]))\n",
    "        \n",
    "        \n",
    "        metadatafiles = listdir(join(exported_directory, 'MetaData'))\n",
    "        metadatafiles =  [k for k in metadatafiles if 'IOManagerConfiguation.xlif' not in k]\n",
    "\n",
    "        for p, meta in enumerate(metadatafiles):\n",
    "            print(meta)\n",
    "            mydoc = minidom.parse(join(exported_directory, 'MetaData',meta) )\n",
    "            tile =[]\n",
    "            x =[]\n",
    "            y =[]\n",
    "            items = mydoc.getElementsByTagName('Tile')\n",
    "            for el, elem in enumerate(items):\n",
    "                tile.append(el)\n",
    "                x.append(float(elem.attributes['PosX'].value))\n",
    "                y.append(float(elem.attributes['PosY'].value))\n",
    "            unique_tiles = list(np.unique(tile))\n",
    "            x_reformatted = (x[:len(unique_tiles)])    \n",
    "            y_reformatted = (y[:len(unique_tiles)])     \n",
    "            dictionary = {'x': x_reformatted, 'y': y_reformatted}  \n",
    "\n",
    "            df = pd.DataFrame(dictionary)\n",
    "            df['x'] =((df.x-np.min(df.x))/.000000321) + 1\n",
    "            df['y'] =((df.y-np.min(df.y))/.000000321) + 1\n",
    "            positions = np.array(df).astype(int)\n",
    "            df.to_csv(directory_base +'/'+ folder + '/coords.csv')\n",
    "            \n",
    "        with tifffile.TiffWriter((output_directory +'/'+ folder + '.ome.tiff'), bigtiff=True) as tif:\n",
    "            for i in tqdm(range(len(tiles))):\n",
    "                position = positions[i]\n",
    "                tile = tiles[i]\n",
    "\n",
    "                tile_filtered = [k for k in onlytifs if 's'+tile+'_' in k]\n",
    "                tile_filtered =  [k for k in tile_filtered if '._' not in k]\n",
    "\n",
    "                stacked = np.empty((5, 2048, 2048))\n",
    "                for n,image_file in enumerate(sorted(tile_filtered)):\n",
    "                    try: \n",
    "                        image_int = tifffile.imread(join(exported_directory,image_file))\n",
    "                    except IndexError: \n",
    "                        image_int = np.empty((2048, 2048))\n",
    "                    stacked[n] = image_int.astype('uint16')\n",
    "                pixel_size = 0.1625\n",
    "                metadata = {\n",
    "                                'Pixels': {\n",
    "                                    'PhysicalSizeX': pixel_size,\n",
    "                                    'PhysicalSizeXUnit': 'µm',\n",
    "                                    'PhysicalSizeY': pixel_size,\n",
    "                                    'PhysicalSizeYUnit': 'µm'\n",
    "                                },\n",
    "                                'Plane': {\n",
    "                                    'PositionX': [position[0]*pixel_size]*stacked.shape[0],\n",
    "                                    'PositionY': [position[1]*pixel_size]*stacked.shape[0]\n",
    "                                }\n",
    "\n",
    "                            }\n",
    "                tif.write(stacked.astype('uint16'),metadata=metadata)\n",
    "\n",
    "\n",
    "import ashlar.scripts.ashlar as ashlar\n",
    "import pathlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def ashlar_wrapper(\n",
    "    files, \n",
    "    output='', \n",
    "    align_channel=1, \n",
    "    flip_x=False, \n",
    "    flip_y=True, \n",
    "    output_channels=None, \n",
    "    maximum_shift=500, \n",
    "    filter_sigma=5.0, \n",
    "    filename_format='Round{cycle}_{channel}.tif',\n",
    "    pyramid=False,\n",
    "    tile_size=None,\n",
    "    ffp=False,\n",
    "    dfp=False,\n",
    "    plates=False,\n",
    "    quiet=False,\n",
    "    version=False):\n",
    "\n",
    "    ashlar.configure_terminal()\n",
    "    \n",
    "    filepaths = files\n",
    "    output_path = pathlib.Path(output)\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")   \n",
    "\n",
    "    # make directory\n",
    "    if not os.path.exists(output):\n",
    "        os.makedirs(output)\n",
    "\n",
    "    if tile_size and not pyramid:\n",
    "        ashlar.print_error(\"--tile-size can only be used with --pyramid\")\n",
    "        return 1\n",
    "    if tile_size is None:\n",
    "        # Implement default value logic as mentioned in argparser setup above.\n",
    "        tile_size = tile_size\n",
    "\n",
    "    ffp_paths = ffp\n",
    "    if ffp_paths:\n",
    "        if len(ffp_paths) not in (0, 1, len(filepaths)):\n",
    "            ashlar.print_error(\n",
    "                \"Wrong number of flat-field profiles. Must be 1, or {}\"\n",
    "                \" (number of input files)\".format(len(filepaths))\n",
    "            )\n",
    "            return 1\n",
    "        if len(ffp_paths) == 1:\n",
    "            ffp_paths = ffp_paths * len(filepaths)\n",
    "\n",
    "    dfp_paths = dfp\n",
    "    if dfp_paths:\n",
    "        if len(dfp_paths) not in (0, 1, len(filepaths)):\n",
    "            ashlar.print_error(\n",
    "                \"Wrong number of dark-field profiles. Must be 1, or {}\"\n",
    "                \" (number of input files)\".format(len(filepaths))\n",
    "            )\n",
    "            return 1\n",
    "        if len(dfp_paths) == 1:\n",
    "            dfp_paths = dfp_paths * len(filepaths)\n",
    "\n",
    "    aligner_args = {}\n",
    "    aligner_args['channel'] = align_channel\n",
    "    aligner_args['verbose'] = not quiet\n",
    "    aligner_args['max_shift'] = maximum_shift\n",
    "    aligner_args['filter_sigma'] = filter_sigma\n",
    "\n",
    "    mosaic_args = {}\n",
    "    if output_channels:\n",
    "        mosaic_args['channels'] = output_channels\n",
    "    if pyramid:\n",
    "        mosaic_args['tile_size'] = tile_size\n",
    "    if quiet is False:\n",
    "        mosaic_args['verbose'] = True\n",
    "\n",
    "    try:\n",
    "        if plates:\n",
    "            return ashlar.process_plates(\n",
    "                filepaths, output_path, filename_format, flip_x,\n",
    "                flip_y, ffp_paths, dfp_paths, aligner_args, mosaic_args,\n",
    "                pyramid, quiet\n",
    "            )\n",
    "        else:\n",
    "            mosaic_path_format = str(output_path / filename_format)\n",
    "            return ashlar.process_single(\n",
    "                filepaths, mosaic_path_format, flip_x, flip_y,\n",
    "                ffp_paths, dfp_paths, aligner_args, mosaic_args, pyramid,\n",
    "                quiet\n",
    "            )\n",
    "    except ashlar.ProcessingError as e:\n",
    "        ashlar.print_error(str(e))\n",
    "        return 1\n",
    "\n",
    "def reshape_split(image: np.ndarray, kernel_size: tuple):\n",
    "        \n",
    "    img_height, img_width = image.shape\n",
    "    tile_height, tile_width = kernel_size\n",
    "    \n",
    "    tiled_array = image.reshape(img_height // tile_height, \n",
    "                               tile_height, \n",
    "                               img_width // tile_width, \n",
    "                               tile_width)\n",
    "    \n",
    "    tiled_array = tiled_array.swapaxes(1,2)\n",
    "    return tiled_array\n",
    "\n",
    "def tile_stitched_images(image_path,outpath, tile_dim=2000, file_type = 'tif', old_stiched_name = False):\n",
    "    \"\"\"\n",
    "    used to tile stitched images\n",
    "    \n",
    "    input the directory to the files that you want to tile. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(outpath):\n",
    "            os.makedirs(outpath)\n",
    "            \n",
    "    images = os.listdir(image_path)\n",
    "    images =  [k for k in images if '._' not in k]\n",
    "    \n",
    "    if file_type=='mat':\n",
    "        images =  [k for k in images if '.tif.mat' in k] \n",
    "    else: \n",
    "        images =  [k for k in images if '.tif' in k] \n",
    "\n",
    "    for image_file in sorted(images):\n",
    "        try: \n",
    "            if file_type == 'mat':\n",
    "                image = mat73.loadmat(image_path +'/'+ image_file)['I']\n",
    "                cycle = ''.join(filter(str.isdigit, image_file.split('_')[1]))\n",
    "                channel = ''.join(filter(str.isdigit, image_file.split('_')[2].split('-')[1].split('.')[0]))\n",
    "            else:\n",
    "                if old_stiched_name == True:\n",
    "                    print('old names')\n",
    "                    image = tifffile.imread(image_path +'/'+ image_file)\n",
    "                    cycle = str(int(''.join(filter(str.isdigit, image_file.split('_')[1])))-1)\n",
    "                    channel = str(int(''.join(filter(str.isdigit, image_file.split('-')[1])))-1)\n",
    "                    print(cycle)\n",
    "                    print(channel)\n",
    "                else: \n",
    "                    image = tifffile.imread(image_path +'/'+ image_file)\n",
    "                    cycle = ''.join(filter(str.isdigit, image_file.split('_')[0]))\n",
    "                    channel = ''.join(filter(str.isdigit, image_file.split('_')[1]))\n",
    "\n",
    "           \n",
    "            \n",
    "            print('tiling: ' + image_file)\n",
    "            \n",
    "            image_pad = cv2.copyMakeBorder( image, top = 0, bottom =math.ceil(image.shape[0]/tile_dim)*tile_dim-image.shape[0], left =0, right = math.ceil(image.shape[1]/tile_dim)*tile_dim-image.shape[1], borderType = cv2.BORDER_CONSTANT)\n",
    "            image_split = reshape_split(image_pad,(tile_dim,tile_dim))\n",
    "            nrows, ncols, dim1, dim2 = image_split.shape\n",
    "            x = []\n",
    "            y = []\n",
    "            directory = outpath +'/'+'Base_'+str(int(cycle)+1)+'_stitched-'+str(int(channel)+1) \n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory) \n",
    "            count = 0\n",
    "            for i in range(nrows):\n",
    "                for j in range(ncols):\n",
    "                    count = count+1                \n",
    "                    x.append(j*tile_dim)\n",
    "                    y.append(i*tile_dim)\n",
    "                    \n",
    "                    tifffile.imwrite(directory + '/' +'tile'+str(count)+'.tif',image_split[i][j])\n",
    "        except KeyError:\n",
    "            continue\n",
    "                \n",
    "    tile_pos = pd.DataFrame()\n",
    "    tile_pos['x'] = x\n",
    "    tile_pos['y'] = y\n",
    "\n",
    "    tile_pos.to_csv(outpath+'/'+'tilepos.csv', header=False, index=False)\n",
    "    return\n",
    "def preprocessing_main_leica(input_dirs, \n",
    "                            output_location,\n",
    "                            regions_to_process = 2, \n",
    "                            align_channel = 4, \n",
    "                            tile_dimension = 6000, \n",
    "                            mip = True):\n",
    "\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    \n",
    "    if mip == True:\n",
    "        leica_mipping(input_dirs=input_dirs, output_dir_prefix = output_location)\n",
    "    else: \n",
    "        print('not mipping')\n",
    "        \n",
    "    if regions_to_process > 1:\n",
    "        for i in range(regions_to_process):\n",
    "            path = output_location +'_R'+str(i+1)\n",
    "            \n",
    "            # create leica OME_tiffs\n",
    "            leica_OME_tiff(directory_base = path+'/preprocessing/mipped/', \n",
    "                                            output_directory = path+'/preprocessing/OME_tiffs/')\n",
    "            \n",
    "            # align and stitch images\n",
    "            OME_tiffs = os.listdir(path+'/preprocessing/OME_tiffs/')\n",
    "            OME_tiffs = [path+'/preprocessing/OME_tiffs/' + sub for sub in OME_tiffs]\n",
    "            ashlar_wrapper(files = OME_tiffs, \n",
    "                                            output = path+'/preprocessing/stitched/', \n",
    "                                            align_channel=align_channel)\n",
    "            \n",
    "            # retile stitched images\n",
    "            tile_stitched_images(image_path = path+'/preprocessing/stitched/',\n",
    "                                    outpath = path+'/preprocessing/ReslicedTiles/', \n",
    "                                    tile_dim=tile_dimension)\n",
    "\n",
    "    \n",
    "    else: \n",
    "        path = output_location\n",
    "\n",
    "        # create leica OME_tiffs\n",
    "        leica_OME_tiff(directory_base = path+'/preprocessing/mipped/', \n",
    "                                        output_directory = path+'/preprocessing/OME_tiffs/')\n",
    "\n",
    "        # align and stitch images\n",
    "        OME_tiffs = os.listdir(path+'/preprocessing/OME_tiffs/')\n",
    "        OME_tiffs = [path+'/preprocessing/OME_tiffs/' + sub for sub in OME_tiffs]\n",
    "\n",
    "        ashlar_wrapper(files = OME_tiffs, \n",
    "                                        output = path+'/preprocessing/stitched/', \n",
    "                                        align_channel=align_channel)\n",
    "\n",
    "        # retile stitched images\n",
    "        tile_stitched_images(image_path = path+'/preprocessing/stitched/',\n",
    "                                outpath = path+'/preprocessing/ReslicedTiles/', \n",
    "                                tile_dim=tile_dimension)\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1776ef15-fb1a-4f23-80b6-2d04999ec8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 3725.79it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 3830.54it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 1086.46it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 3409.71it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 3551.64it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 3211.11it/s]\n",
      "100%|██████████| 55/55 [00:00<00:00, 3970.37it/s]\n",
      "100%|██████████| 55/55 [00:00<00:00, 3776.30it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 4727.50it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 4103.44it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 995.24it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 3935.54it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 3166.19it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 3365.94it/s]\n",
      "100%|██████████| 55/55 [13:16<00:00, 14.48s/it]\n",
      "100%|██████████| 55/55 [13:20<00:00, 14.55s/it]\n",
      "100%|██████████| 28/28 [00:00<00:00, 5698.78it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 4690.12it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 3776.60it/s]\n",
      "100%|██████████| 48/48 [07:49<00:00,  9.78s/it]\n",
      "100%|██████████| 60/60 [14:51<00:00, 14.86s/it]\n",
      "100%|██████████| 60/60 [14:38<00:00, 14.64s/it]\n",
      "100%|██████████| 55/55 [13:40<00:00, 14.92s/it]\n",
      "100%|██████████| 55/55 [13:24<00:00, 14.63s/it]\n",
      "100%|██████████| 28/28 [08:49<00:00, 18.90s/it]\n",
      "100%|██████████| 28/28 [10:27<00:00, 22.40s/it]\n",
      "100%|██████████| 48/48 [10:43<00:00, 13.41s/it]\n",
      "100%|██████████| 48/48 [09:48<00:00, 12.25s/it]\n",
      "100%|██████████| 60/60 [12:35<00:00, 12.59s/it]\n",
      "100%|██████████| 60/60 [12:27<00:00, 12.46s/it]\n",
      "100%|██████████| 55/55 [11:42<00:00, 12.78s/it]\n",
      "100%|██████████| 55/55 [12:22<00:00, 13.50s/it]\n",
      "100%|██████████| 28/28 [05:32<00:00, 11.89s/it]\n",
      "100%|██████████| 28/28 [05:31<00:00, 11.82s/it]\n",
      "100%|██████████| 48/48 [09:19<00:00, 11.66s/it]\n",
      "100%|██████████| 48/48 [09:20<00:00, 11.67s/it]\n",
      "100%|██████████| 60/60 [11:44<00:00, 11.74s/it]\n",
      "100%|██████████| 60/60 [11:38<00:00, 11.63s/it]\n",
      "100%|██████████| 55/55 [10:43<00:00, 11.70s/it]\n",
      "100%|██████████| 55/55 [10:42<00:00, 11.69s/it]\n",
      "100%|██████████| 28/28 [06:40<00:00, 14.29s/it]\n",
      "100%|██████████| 28/28 [06:20<00:00, 13.60s/it]\n",
      "100%|██████████| 48/48 [10:52<00:00, 13.60s/it]\n",
      "100%|██████████| 48/48 [10:55<00:00, 13.65s/it]\n",
      "100%|██████████| 60/60 [13:37<00:00, 13.63s/it]\n",
      "100%|██████████| 60/60 [13:40<00:00, 13.67s/it]\n",
      "100%|██████████| 55/55 [12:27<00:00, 13.59s/it]\n",
      "100%|██████████| 55/55 [12:31<00:00, 13.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region1.xlif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:28<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region1.xlif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:32<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region1.xlif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:34<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region1.xlif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:34<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region1.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:35<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region1.xlif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:36<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle 0:\n",
      "    reading /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/OME_tiffs/Base_1.ome.tiff\n",
      "    assembling thumbnail 28/28\n",
      "    quantifying alignment error 1000/1000\n",
      "    aligning edge 45/45\n",
      "    Channel 0:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round0_0.tif\n",
      "    Channel 1:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round0_1.tif\n",
      "    Channel 2:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round0_2.tif\n",
      "    Channel 3:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round0_3.tif\n",
      "    Channel 4:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round0_4.tif\n",
      "Cycle 1:\n",
      "    reading /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/OME_tiffs/Base_2.ome.tiff\n",
      "    assembling thumbnail 28/28\n",
      "    estimated cycle offset [y x] = [ 0. -2.]\n",
      "    aligning tile 28/28\n",
      "    Channel 0:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round1_0.tif\n",
      "    Channel 1:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round1_1.tif\n",
      "    Channel 2:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round1_2.tif\n",
      "    Channel 3:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round1_3.tif\n",
      "    Channel 4:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round1_4.tif\n",
      "Cycle 2:\n",
      "    reading /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/OME_tiffs/Base_3.ome.tiff\n",
      "    assembling thumbnail 28/28\n",
      "    estimated cycle offset [y x] = [-61.  55.]\n",
      "    aligning tile 28/28\n",
      "    Channel 0:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round2_0.tif\n",
      "    Channel 1:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round2_1.tif\n",
      "    Channel 2:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round2_2.tif\n",
      "    Channel 3:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round2_3.tif\n",
      "    Channel 4:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round2_4.tif\n",
      "Cycle 3:\n",
      "    reading /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/OME_tiffs/Base_4.ome.tiff\n",
      "    assembling thumbnail 28/28\n",
      "    estimated cycle offset [y x] = [ 0. -5.]\n",
      "    aligning tile 28/28\n",
      "    Channel 0:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round3_0.tif\n",
      "    Channel 1:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round3_1.tif\n",
      "    Channel 2:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round3_2.tif\n",
      "    Channel 3:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round3_3.tif\n",
      "    Channel 4:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round3_4.tif\n",
      "Cycle 4:\n",
      "    reading /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/OME_tiffs/Base_5.ome.tiff\n",
      "    assembling thumbnail 28/28\n",
      "    estimated cycle offset [y x] = [-1. -2.]\n",
      "    aligning tile 28/28\n",
      "    Channel 0:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round4_0.tif\n",
      "    Channel 1:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round4_1.tif\n",
      "    Channel 2:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round4_2.tif\n",
      "    Channel 3:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round4_3.tif\n",
      "    Channel 4:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round4_4.tif\n",
      "Cycle 5:\n",
      "    reading /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/OME_tiffs/Base_6.ome.tiff\n",
      "    assembling thumbnail 28/28\n",
      "    estimated cycle offset [y x] = [-1. -4.]\n",
      "    aligning tile 28/28\n",
      "    Channel 0:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round5_0.tif\n",
      "    Channel 1:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round5_1.tif\n",
      "    Channel 2:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round5_2.tif\n",
      "    Channel 3:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round5_3.tif\n",
      "    Channel 4:\n",
      "        merging tile 28/28\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R1/preprocessing/stitched/Round5_4.tif\n",
      "tiling: Round0_0.tif\n",
      "tiling: Round0_1.tif\n",
      "tiling: Round0_2.tif\n",
      "tiling: Round0_3.tif\n",
      "tiling: Round0_4.tif\n",
      "tiling: Round1_0.tif\n",
      "tiling: Round1_1.tif\n",
      "tiling: Round1_2.tif\n",
      "tiling: Round1_3.tif\n",
      "tiling: Round1_4.tif\n",
      "tiling: Round2_0.tif\n",
      "tiling: Round2_1.tif\n",
      "tiling: Round2_2.tif\n",
      "tiling: Round2_3.tif\n",
      "tiling: Round2_4.tif\n",
      "tiling: Round3_0.tif\n",
      "tiling: Round3_1.tif\n",
      "tiling: Round3_2.tif\n",
      "tiling: Round3_3.tif\n",
      "tiling: Round3_4.tif\n",
      "tiling: Round4_0.tif\n",
      "tiling: Round4_1.tif\n",
      "tiling: Round4_2.tif\n",
      "tiling: Round4_3.tif\n",
      "tiling: Round4_4.tif\n",
      "tiling: Round5_0.tif\n",
      "tiling: Round5_1.tif\n",
      "tiling: Round5_2.tif\n",
      "tiling: Round5_3.tif\n",
      "tiling: Round5_4.tif\n",
      "A1 Region2.xlif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:37<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region2.xlif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:48<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region2.xlif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:45<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region2.xlif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:38<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region2.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:37<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region2.xlif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:38<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle 0:\n",
      "    reading /media/cml/hfsc_processing_2/HFSC_R2/preprocessing/OME_tiffs/Base_1.ome.tiff\n",
      "    assembling thumbnail 28/28\n",
      "    quantifying alignment error 1000/1000\n",
      "    aligning edge 45/45\n",
      "    Channel 0:\n",
      "        merging tile 6/28"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R5/preprocessing/stitched/Round3_2.tif\n",
      "    Channel 3:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R5/preprocessing/stitched/Round3_3.tif\n",
      "    Channel 4:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R5/preprocessing/stitched/Round3_4.tif\n",
      "Cycle 4:\n",
      "    reading /media/cml/hfsc_processing_2/HFSC_R5/preprocessing/OME_tiffs/Base_5.ome.tiff\n",
      "    assembling thumbnail 60/60\n",
      "    estimated cycle offset [y x] = [-2. -1.]\n",
      "    aligning tile 60/60\n",
      "    Channel 0:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R5/preprocessing/stitched/Round4_0.tif\n",
      "    Channel 1:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R5/preprocessing/stitched/Round4_1.tif\n",
      "    Channel 2:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R5/preprocessing/stitched/Round4_2.tif\n",
      "    Channel 3:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R5/preprocessing/stitched/Round4_3.tif\n",
      "    Channel 4:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R5/preprocessing/stitched/Round4_4.tif\n",
      "Cycle 5:\n",
      "    reading /media/cml/hfsc_processing_2/HFSC_R5/preprocessing/OME_tiffs/Base_6.ome.tiff\n",
      "    assembling thumbnail 60/60\n",
      "    estimated cycle offset [y x] = [-3. -2.]\n",
      "    aligning tile 60/60\n",
      "    Channel 0:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R5/preprocessing/stitched/Round5_0.tif\n",
      "    Channel 1:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R5/preprocessing/stitched/Round5_1.tif\n",
      "    Channel 2:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R5/preprocessing/stitched/Round5_2.tif\n",
      "    Channel 3:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R5/preprocessing/stitched/Round5_3.tif\n",
      "    Channel 4:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R5/preprocessing/stitched/Round5_4.tif\n",
      "tiling: Round0_0.tif\n",
      "tiling: Round0_1.tif\n",
      "tiling: Round0_2.tif\n",
      "tiling: Round0_3.tif\n",
      "tiling: Round0_4.tif\n",
      "tiling: Round1_0.tif\n",
      "tiling: Round1_1.tif\n",
      "tiling: Round1_2.tif\n",
      "tiling: Round1_3.tif\n",
      "tiling: Round1_4.tif\n",
      "tiling: Round2_0.tif\n",
      "tiling: Round2_1.tif\n",
      "tiling: Round2_2.tif\n",
      "tiling: Round2_3.tif\n",
      "tiling: Round2_4.tif\n",
      "tiling: Round3_0.tif\n",
      "tiling: Round3_1.tif\n",
      "tiling: Round3_2.tif\n",
      "tiling: Round3_3.tif\n",
      "tiling: Round3_4.tif\n",
      "tiling: Round4_0.tif\n",
      "tiling: Round4_1.tif\n",
      "tiling: Round4_2.tif\n",
      "tiling: Round4_3.tif\n",
      "tiling: Round4_4.tif\n",
      "tiling: Round5_0.tif\n",
      "tiling: Round5_1.tif\n",
      "tiling: Round5_2.tif\n",
      "tiling: Round5_3.tif\n",
      "tiling: Round5_4.tif\n",
      "A1 Region6.xlif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:31<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region6.xlif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:20<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region6.xlif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:20<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region6.xlif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:36<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region6.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:20<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 Region6.xlif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:38<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle 0:\n",
      "    reading /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/OME_tiffs/Base_1.ome.tiff\n",
      "    assembling thumbnail 60/60\n",
      "    quantifying alignment error 1000/1000\n",
      "    aligning edge 101/101\n",
      "    Channel 0:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/stitched/Round0_0.tif\n",
      "    Channel 1:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/stitched/Round0_1.tif\n",
      "    Channel 2:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/stitched/Round0_2.tif\n",
      "    Channel 3:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/stitched/Round0_3.tif\n",
      "    Channel 4:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/stitched/Round0_4.tif\n",
      "Cycle 1:\n",
      "    reading /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/OME_tiffs/Base_2.ome.tiff\n",
      "    assembling thumbnail 60/60\n",
      "    estimated cycle offset [y x] = [1. 0.]\n",
      "    aligning tile 60/60\n",
      "    Channel 0:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/stitched/Round1_0.tif\n",
      "    Channel 1:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/stitched/Round1_1.tif\n",
      "    Channel 2:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/stitched/Round1_2.tif\n",
      "    Channel 3:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/stitched/Round1_3.tif\n",
      "    Channel 4:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/stitched/Round1_4.tif\n",
      "Cycle 2:\n",
      "    reading /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/OME_tiffs/Base_3.ome.tiff\n",
      "    assembling thumbnail 60/60\n",
      "    estimated cycle offset [y x] = [-60.  60.]\n",
      "    aligning tile 60/60\n",
      "    Channel 0:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/stitched/Round2_0.tif\n",
      "    Channel 1:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/stitched/Round2_1.tif\n",
      "    Channel 2:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/stitched/Round2_2.tif\n",
      "    Channel 3:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/stitched/Round2_3.tif\n",
      "    Channel 4:\n",
      "        merging tile 60/60\n",
      "        writing to /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/stitched/Round2_4.tif\n",
      "Cycle 3:\n",
      "    reading /media/cml/hfsc_processing_2/HFSC_R6/preprocessing/OME_tiffs/Base_4.ome.tiff\n",
      "    assembling thumbnail 60/60\n",
      "    estimated cycle offset [y x] = [ 0. -2.]\n",
      "    aligning tile 60/60\n",
      "    Channel 0:\n",
      "        merging tile 54/60"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessing_main_leica(input_dirs = input_dirs, \n",
    "                output_location = output_location,\n",
    "                regions_to_process = 8, \n",
    "                align_channel = 4, \n",
    "                tile_dimension = 4000, \n",
    "                mip = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4668d70-f26f-4df1-b39a-2520b1d00ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISS_preprocessing",
   "language": "python",
   "name": "iss_preprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
